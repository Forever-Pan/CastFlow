OPENAI_BASE_URL="https://api2.aigcbest.top/v1"
OPENAI_API_KEY="sk-k9iA5UVoE9QbLsod6UaMflzIbaU5jVd43fUmadTBHJGy76Pn"
MODEL="grok-4-1-fast-non-reasoning"


# 本地 Qwen 3-4B/8B，假设你用 vLLM 起了 OpenAI 兼容服务
# LOCAL_MODEL_BASE_URL="http://localhost:8003/v1"
# LOCAL_MODEL_NAME="models/windy/rl_qwen3_1.7b_windy/global_step_125/actor/huggingface"           # 或你服务里配置的模型名
# LOCAL_MODEL_API_KEY="EMPTY"           # 如果 vLLM 不校验 key，可随便填


# OPENAI_BASE_URL="http://localhost:8002/v1"
# OPENAI_API_KEY="123"
# MODEL="./models/rl_model/global_step_25/actor/huggingface"