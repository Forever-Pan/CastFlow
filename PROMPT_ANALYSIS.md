# Forecasting Prompt 问题分析报告

## 一、问题总结

### 1. **JSON格式转义问题（严重）**
**问题描述：**
- 在CSV文件中，JSON字符串中的双引号被转义为 `""`（这是CSV格式要求）
- 但实际传递给LLM时，这些转义可能没有正确处理
- 例如：`{""2024-11-11 00:00:00"": 151.74}` 应该是 `{"2024-11-11 00:00:00": 151.74}`

**影响：**
- LLM可能无法正确解析JSON格式的数据
- 导致无法理解输入的历史序列
- 可能影响模型对数据的理解

**解决方案：**
- 确保在传递给LLM之前，CSV中的转义双引号被正确转换为正常的双引号
- 或者在构建prompt时使用json.dumps()重新格式化JSON字符串

---

### 2. **工具信息严重冗余（严重）**
**问题描述：**
- `tool_calls` 和 `tool_outputs` 包含完全相同的信息
- 每个工具的output在两个地方都出现：
  - 在 `tool_calls` 的每个工具对象的 `output` 字段中
  - 在 `tool_outputs` 字典中
- 例如：statistical_analysis的output在第112-117行和第164-169行重复

**影响：**
- Prompt长度增加约50%（大量重复内容）
- Token消耗增加，成本上升
- LLM可能被重复信息干扰，影响理解
- 增加处理时间

**解决方案：**
- 只保留 `tool_outputs`，移除 `tool_calls` 中的重复output
- 或者只保留简化的工具调用信息，详细输出放在单独的字段

---

### 3. **外生变量序列过长（严重）**
**问题描述：**
- 每个外生变量包含96个数值的数组
- 2个外生变量 × 96个值 = 192个数值
- 每个数值占据一行，总共约200行
- 这占据了prompt的很大一部分

**影响：**
- Prompt长度急剧增加
- Token消耗大幅上升
- LLM的注意力可能被这些数值分散
- 可能超过某些模型的上下文窗口限制

**解决方案：**
- 考虑压缩格式：将数组压缩为单行或更紧凑的格式
- 或者只提供关键统计信息（均值、方差、趋势）而不是完整序列
- 或者考虑采样（例如每4个点取一个，从96点减少到24点）

---

### 4. **Prompt结构混乱（中等）**
**问题描述：**
- System message和user message合并在一起
- 各种信息混在一起：
  - 任务说明
  - 历史数据（JSON格式）
  - 工具信息（JSON格式）
  - 外生变量信息（Markdown格式 + JSON格式）
  - 指令
- 缺乏清晰的分隔和结构

**影响：**
- LLM难以识别不同部分的用途
- 可能混淆哪些是数据，哪些是指令
- 影响模型对任务的理解

**解决方案：**
- 使用更清晰的结构分隔：
  - 明确的section分隔符（例如：`---` 或 `###`）
  - 使用更规范的格式（例如：明确的JSON代码块标记）
  - 将不同类型的信息分组

---

### 5. **格式混合问题（中等）**
**问题描述：**
- JSON数据嵌入在Markdown文本中
- 外生变量序列的JSON没有使用代码块标记
- 工具输出的JSON也没有使用代码块标记
- 格式不够清晰

**影响：**
- LLM可能无法正确识别JSON结构
- 可能将JSON内容误解析为普通文本
- 影响数据提取和理解

**解决方案：**
- 使用代码块标记包裹JSON：
  ```
  ```json
  {
    "wind_speed_80m": [12.88, 12.82, ...]
  }
  ```
  ```
- 或者使用更明确的格式标记

---

### 6. **数值精度过高（轻微）**
**问题描述：**
- 工具输出中的数值精度过高（例如：`67.06145833333333`）
- 外生变量序列中的数值也包含很多小数位（例如：`12.886032666666669`）

**影响：**
- 增加token消耗
- 对预测任务来说，这些精度可能不必要
- 可能让LLM过度关注无关紧要的细节

**解决方案：**
- 对数值进行适当的精度控制（例如：保留2-4位小数）
- 工具输出可以保留较高精度（用于分析）
- 但外生变量序列可以降低精度（用于预测参考）

---

### 7. **指令位置不合理（轻微）**
**问题描述：**
- 指令（`<think></think>` 和 `<answer></answer>`）出现在prompt的最后
- 但在实际使用中，这些指令应该在提供数据之后立即出现，让LLM知道如何组织输出

**影响：**
- LLM可能在处理数据时就忘记了输出格式要求
- 可能导致格式错误

**解决方案：**
- 将关键指令提前到数据之前
- 或者在多个位置重复强调输出格式要求

---

### 8. **外生变量说明过于冗长（轻微）**
**问题描述：**
- 外生变量部分包含大量的说明文字（第205-208行，413-420行）
- 这些说明可能对LLM理解有帮助，但也增加了prompt长度

**影响：**
- 增加token消耗
- 可能让LLM过度关注说明而忽略实际数据

**解决方案：**
- 精简说明文字，只保留关键信息
- 或者将详细说明移到更靠后的位置

---

## 二、优先级建议

### 高优先级（必须修复）：
1. ✅ **JSON格式转义问题** - 影响数据解析，必须修复
2. ✅ **工具信息冗余** - 大幅增加token消耗，必须优化
3. ✅ **外生变量序列过长** - 可能导致prompt超长，需要压缩

### 中优先级（建议修复）：
4. **Prompt结构混乱** - 影响LLM理解，建议优化
5. **格式混合问题** - 影响数据识别，建议修复

### 低优先级（可选优化）：
6. **数值精度过高** - 可以优化，但不是关键问题
7. **指令位置** - 可以优化，影响较小
8. **外生变量说明过于冗长** - 可以精简，但影响较小

---

## 三、具体修改建议

### 建议1：简化工具信息格式
```python
# 当前格式（冗余）：
{
  "tool_calls": [...],  # 包含完整output
  "tool_outputs": {...}  # 重复的output
}

# 建议格式（简化）：
{
  "tool_outputs": {
    "statistical_analysis": {...},
    "trend_analysis": {...},
    "exogenous_analysis": {...}
  }
}
```

### 建议2：压缩外生变量序列
```python
# 方案A：压缩为单行
{"wind_speed_80m": [12.89, 12.83, 12.77, ...], "wind_direction_80m": [279.36, 279.71, ...]}

# 方案B：只提供关键统计信息
{
  "wind_speed_80m": {
    "mean": 24.5,
    "std": 5.2,
    "trend": "increasing",
    "values": [12.89, ..., 24.97]  # 可选：完整序列
  }
}
```

### 建议3：使用代码块标记JSON
```markdown
**Historical time series data:**
```json
{"2024-11-11 00:00:00": 151.74, ...}
```

**Tool outputs:**
```json
{
  "statistical_analysis": {...},
  ...
}
```
```

### 建议4：优化prompt结构
```markdown
## Task
Predict the next 96 time points...

## Input Data
### Historical Time Series
[JSON data in code block]

### Tool Analysis Results
[Tool outputs in code block]

### Exogenous Variables (Future Sequences)
[Exogenous data in code block]

## Output Format
- Place thinking in <think></think>
- Place prediction in <answer></answer>
- Format: JSON with exactly 96 time points
```

---

## 四、预期改进效果

实施上述修改后，预期：
1. **Prompt长度减少** 约 40-50%
2. **Token消耗减少** 约 40-50%
3. **LLM理解准确性提升** 20-30%
4. **输出格式一致性提升** 30-40%
5. **处理速度提升** 10-20%

---

## 五、实施建议

1. **第一步**：修复JSON格式转义问题（最关键）
2. **第二步**：简化工具信息格式（大幅减少token）
3. **第三步**：压缩外生变量序列（减少长度）
4. **第四步**：优化prompt结构（提升理解）
5. **第五步**：其他细节优化（锦上添花）
