# -*- coding: utf-8 -*-
"""
ç®€åŒ–çš„è®­ç»ƒè„šæœ¬ï¼šä½¿ç”¨ LiteAgent è¿›è¡Œè®­ç»ƒ
pkill -f "python train.py"
pkill -f AgentLightning-AgentOpsServer
ray stop --force
"""

import argparse
import os
import pandas as pd
from pathlib import Path
from typing import Dict, Any

import agentlightning as agl
from agentlightning.adapter import TracerTraceToTriplet

from rl_agent import LiteAgent

from pathlib import Path
import shutil

# ä¿®å¤CUDA_HOMEç¯å¢ƒå˜é‡ï¼ˆé¿å…DeepSpeedå¯¼å…¥é”™è¯¯ï¼‰
# æ£€æŸ¥å¹¶è®¾ç½®æ­£ç¡®çš„CUDA_HOMEè·¯å¾„
nvcc_path = shutil.which("nvcc")
if nvcc_path:
    cuda_home = str(Path(nvcc_path).parent.parent)
    os.environ["CUDA_HOME"] = cuda_home
else:
    # å¦‚æœnvccä¸åœ¨PATHä¸­ï¼Œå°è¯•å¸¸è§çš„CUDAè·¯å¾„
    common_cuda_paths = [
        "/usr/local/cuda",
        "/usr/local/cuda-12.6",
        "/usr/local/cuda-12",
        "/usr/local/cuda-11.8",
    ]
    for cuda_path in common_cuda_paths:
        nvcc_file = Path(cuda_path) / "bin" / "nvcc"
        if nvcc_file.exists():
            os.environ["CUDA_HOME"] = cuda_path
            # åŒæ—¶æ·»åŠ åˆ°PATHä»¥ä¾¿åç»­ä½¿ç”¨
            os.environ["PATH"] = f"{cuda_path}/bin:{os.environ.get('PATH', '')}"
            break

# æ¸…ç†CUDA_HOMEä¸­çš„é”™è¯¯æ ¼å¼ï¼ˆç§»é™¤å¼€å¤´çš„å†’å·ç­‰ï¼‰
if "CUDA_HOME" in os.environ:
    cuda_home = os.environ["CUDA_HOME"].strip()
    # ç§»é™¤å¼€å¤´çš„å†’å·
    if cuda_home.startswith(":"):
        cuda_home = cuda_home[1:]
    # å¦‚æœæœ‰å¤šä¸ªè·¯å¾„ï¼ˆç”¨å†’å·åˆ†éš”ï¼‰ï¼Œå–ç¬¬ä¸€ä¸ªæœ‰æ•ˆè·¯å¾„
    if ":" in cuda_home:
        cuda_home = cuda_home.split(":")[0]
    os.environ["CUDA_HOME"] = cuda_home

if "TRITON_CACHE_DIR" not in os.environ:
    os.environ["TRITON_CACHE_DIR"] = "/tmp/triton_cache_" + os.getlogin()

os.environ["WANDB_MODE"] = "offline"

def get_training_config(dataset_path: str, model_path: str, output_dir: str) -> Dict[str, Any]:
    """è·å–è®­ç»ƒé…ç½®ï¼ˆå·²æ ¹æ®æœ€æ–°æŒ‡ä»¤è°ƒæ•´æ¢¯åº¦èŒƒæ•°ä¸ KL çº¦æŸï¼‰"""
    return {
        "algorithm": {
            "adv_estimator": "grpo",
            "use_kl_in_reward": True, 
            "kl_coeff": 0.0,  # ğŸ’¡ è°ƒä½/å…³é—­å¥–åŠ±ä¸­çš„ KL æƒ©ç½šç³»æ•°
            "kl_ctrl": {
                "type": "fixed",
                "kl_coef": 0.0, # ğŸ’¡ æŒ‡ä»¤è¦æ±‚ï¼šå®Œå…¨å…³é—­ KL æ§åˆ¶
            }
        },
        "data": {
            "train_files": dataset_path,
            "val_files": dataset_path,
            "train_batch_size": 8,
            "max_prompt_length": 10000,
            "max_response_length": 5000,
            "truncation": "left",
        },
        "actor_rollout_ref": {
            "rollout": {
                "free_cache_engine": True,
                "tensor_model_parallel_size": 1,
                "n": 4,
                "log_prob_micro_batch_size_per_gpu": 2,
                "name": "vllm",
                "gpu_memory_utilization": 0.65,
                "max_num_seqs": 256,
                "max_num_batched_tokens": 35000,
                "enable_chunked_prefill": True,
                "sampling_params": {
                    "temperature": 1.3,  # æé«˜æ¸©åº¦å¢åŠ å¤šæ ·æ€§ï¼ˆä»1.0æé«˜åˆ°1.3ï¼‰
                    "top_p": 0.85,       # é™ä½top_på¢åŠ é‡‡æ ·èŒƒå›´ï¼ˆä»0.9é™åˆ°0.85ï¼‰
                    "top_k": 100,        # é™ä½top_kå¢åŠ å€™é€‰tokenå¤šæ ·æ€§ï¼ˆä»150é™åˆ°100ï¼‰
                    "repetition_penalty": 1.05,  # æ·»åŠ é‡å¤æƒ©ç½šï¼Œé¿å…è¿‡åº¦é‡å¤reference_prediction
                },
                "engine_kwargs": {
                    "vllm": {
                        "enable_auto_tool_choice": True,
                        "tool_call_parser": "hermes",
                    }
                },
            },
            "actor": {
                "ppo_mini_batch_size": 8,
                "ppo_micro_batch_size_per_gpu": 2,
                "use_kl_loss": False,      # ğŸ’¡ æŒ‡ä»¤è¦æ±‚ï¼šå…³é—­ KL Loss
                "kl_loss_coef": 0.0,      # ğŸ’¡ æŒ‡ä»¤è¦æ±‚ï¼šç³»æ•°è®¾ä¸º 0
                "grad_clip": 2.0,         # ğŸ’¡ æŒ‡ä»¤è¦æ±‚ï¼šè°ƒå¤§æ¢¯åº¦è£å‰ªé˜ˆå€¼
                "clip_ratio_low": 0.2,    # ğŸ’¡ PPO è£å‰ªä¸‹é™
                "clip_ratio_high": 0.28,  # ğŸ’¡ PPO è£å‰ªä¸Šé™
                "clip_ratio_c": 10.0,     # ğŸ’¡ è¾ƒå¤§çš„è£å‰ªå¸¸æ•°ï¼Œå‡å°‘çº¦æŸ
                "optim": {
                    "lr": 2e-6,
                    "weight_decay": 0.01
                },
                "checkpoint": {
                    "save_contents": ["hf_model"],
                    "load_contents": ["hf_model"],
                    "async_save": False,
                },
            },
            "ref": {
                "log_prob_micro_batch_size_per_gpu": 2,
            },
            "model": {
                "path": model_path,
                "enable_gradient_checkpointing": True,
            },
        },
        "trainer": {
            "n_gpus_per_node": 1,
            "val_before_train": False,
            "logger": ["console", "wandb"],
            "project_name": "VLMTimeSSeriesAgent",
            "experiment_name": "vlm_tsss_training",
            "nnodes": 1,
            "test_freq": 1000,
            "total_epochs": 3,
            "save_freq": 280,
            "default_local_dir": output_dir,
        },
    }
## /data/wuli_error/.cache/huggingface/hub/models--Qwen--Qwen3-1.7B/snapshots/70d244cc86ccca08cf5af4e1e306ecf908b1ad5e

def train_fine_grained(dataset_path: str, model_path: str, output_dir: str, port: int):
    """
    ä½¿ç”¨ LiteAgent è¿›è¡Œè®­ç»ƒ
    
    Args:
        dataset_path: æ•°æ®é›†è·¯å¾„ï¼ˆparquetæ–‡ä»¶ï¼‰
        model_path: æ¨¡å‹è·¯å¾„
        output_dir: è¾“å‡ºç›®å½•
        port: è®­ç»ƒå™¨ç«¯å£å·
    """
    # 1. åŠ è½½é…ç½®
    config = get_training_config(dataset_path, model_path, output_dir)
    
    # 2. åˆ›å»º Agent
    agent = LiteAgent(
        rollout_output_dir="./rollouts_1"
    )
    
    # 3. åˆ›å»ºç®—æ³•å’Œè®­ç»ƒå™¨
    algorithm = agl.VERL(config)
    
    adapter = TracerTraceToTriplet(
        agent_match=None,  # None è¡¨ç¤ºåŒ¹é…æ‰€æœ‰ agent èŠ‚ç‚¹
        llm_call_match=r"openai\.chat\.completion",  # åŒ¹é… OpenAI chat completion è°ƒç”¨
        _skip_empty_token_spans=True
    )
    trainer = agl.Trainer(
        n_runners=64,
        algorithm=algorithm,
        adapter=adapter,
        port=port
    )
    
    # 4. åŠ è½½æ•°æ®é›†
    train_file = config["data"]["train_files"]
    val_file = config["data"]["val_files"]
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not Path(train_file).exists():
        raise FileNotFoundError(f"è®­ç»ƒæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {train_file}")
    if not Path(val_file).exists():
        raise FileNotFoundError(f"éªŒè¯æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {val_file}")
    
    train_df = pd.read_parquet(train_file)
    val_df = pd.read_parquet(val_file)
    
    # æ£€æŸ¥æ•°æ®æ˜¯å¦ä¸ºç©º
    if len(train_df) == 0:
        raise ValueError(f"è®­ç»ƒæ•°æ®æ–‡ä»¶ä¸ºç©º: {train_file}")
    if len(val_df) == 0:
        raise ValueError(f"éªŒè¯æ•°æ®æ–‡ä»¶ä¸ºç©º: {val_file}")
    
    # æ£€æŸ¥å¿…éœ€çš„åˆ—æ˜¯å¦å­˜åœ¨
    required_columns = ["prompt", "ground_truth"]
    missing_columns = [col for col in required_columns if col not in train_df.columns]
    if missing_columns:
        raise ValueError(f"è®­ç»ƒæ•°æ®ç¼ºå°‘å¿…éœ€çš„åˆ—: {missing_columns}")
    
    train_data = train_df.to_dict(orient="records")
    val_data = val_df.to_dict(orient="records")
    
    # 5. å¼€å§‹è®­ç»ƒ
    trainer.fit(agent, train_dataset=train_data, val_dataset=val_data)


def parse_args():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description="RL Agent Training Script")
    parser.add_argument(
        "--dataset_path",
        type=str,
        default="./datasets/SFT_RL_bank/grok_merge.parquet",
        help="Path to the training dataset (parquet file)"
    )
    parser.add_argument(
        "--model_path",
        type=str,
        default="./models/merge/sft_qwen3_0.6B",
        help="Path to the model directory"
    )
    parser.add_argument(
        "--output_dir",
        type=str,
        default="./models/merge/sft_rl_qwen3_0.6B_new_reward",
        help="Output directory for trained model"
    )
    parser.add_argument(
        "--port",
        type=int,
        default=46549,
        help="Port number for the trainer (default: 32519)"
    )
    return parser.parse_args()


if __name__ == "__main__":
    args = parse_args()
    
    # éªŒè¯è·¯å¾„æ˜¯å¦å­˜åœ¨
    if not Path(args.dataset_path).exists():
        raise FileNotFoundError(f"æ•°æ®é›†æ–‡ä»¶ä¸å­˜åœ¨: {args.dataset_path}")
    if not Path(args.model_path).exists():
        raise FileNotFoundError(f"æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {args.model_path}")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    Path(args.output_dir).mkdir(parents=True, exist_ok=True)
    
    train_fine_grained(
        dataset_path=args.dataset_path,
        model_path=args.model_path,
        output_dir=args.output_dir,
        port=args.port
    )

